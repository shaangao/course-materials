{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonclindaniel/LargeScaleComputing_A21/blob/main/in-class-activities/02_Midway_MPI/mpi4py_on_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ZSY7D-7OwS"
      },
      "source": [
        "First, install mpi4py in the Colab notebook environment. Note that you will have to run this cell to reinstall it every time you start a new Colab session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8TZn4JxOoNx",
        "outputId": "be7487f9-90e3-4813-f88d-b5cd3274a1d1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.1.tar.gz (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 5.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.1-cp37-cp37m-linux_x86_64.whl size=2180608 sha256=8d7dd7fabdf107a8fee20e0194d0358631fbe9dc18302d0d903ad5bbd9d18dc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/be/c0/2b0347be1de5cd8ca9fe67da7ec8c3fe8930fcb6b0df6f2255\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.1\n"
          ]
        }
      ],
      "source": [
        "! pip install mpi4py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO9ute3r7hZ1"
      },
      "source": [
        "Then, we can use Jupyter magic to write the contents of a cell into a Python mpi4py program that we can run below using `mpirun`. Note that you need to allow it to \"run as root\" here in the Colab notebook in order for your code to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unl5rf9WzQMP",
        "outputId": "da353023-7647-4168-ac17-10a07c436c79",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing hello_world.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile hello_world.py \n",
        "from mpi4py import MPI\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "size = comm.Get_size()\n",
        "rank = comm.Get_rank()\n",
        "name = MPI.Get_processor_name()\n",
        "\n",
        "print(\"Hello, World! I am process %d of %d on %s.\" % (rank, size, name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWs08SJ3zfw6",
        "outputId": "f0c256d0-b4ec-49ea-cb54-450bd81ee5f0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, World! I am process 3 of 4 on 861fbdc3fdd7.\n",
            "Hello, World! I am process 1 of 4 on 861fbdc3fdd7.\n",
            "Hello, World! I am process 2 of 4 on 861fbdc3fdd7.\n",
            "Hello, World! I am process 0 of 4 on 861fbdc3fdd7.\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -n 4 python hello_world.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "! mpirun --allow-run-as-root --oversubscribe -n 4 python hello_world.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whEbt4UcWpHu"
      },
      "source": [
        "Note that while the program is run on different threads (4 MPI processes), Colab is only giving us one processor, so the same processor name is listed for each thread. We're unlikely to get a speed-up if we parallelize in this way, but it can be a nice interactive spot to debug our code before we run it on the Midway Cluster.\n",
        "\n",
        "Below is the parallel random walk simulation from the `in-class-activities/02_Midway_MPI` directory on GitHub. You can view the plot that it produces (after running the program for yourself) by clicking on the file folder icon tab on the right-hand side of this screen and clicking the r_walk*.png image file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPLFRa1Bkq2A",
        "outputId": "d5922a27-bd6c-403a-ea5a-786fc90ab747",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi_rand_walk.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi_rand_walk.py \n",
        "from mpi4py import MPI\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def sim_rand_walks_parallel(n_runs):\n",
        "    # Get rank of process and overall size of communicator:\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    # Start time:\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Evenly distribute number of simulation runs across processes\n",
        "    N = int(n_runs / size)\n",
        "\n",
        "    # Simulate N random walks and specify as a NumPy Array\n",
        "    r_walks = []\n",
        "    for i in range(N):\n",
        "        steps = np.random.normal(loc=0, scale=1, size=100)\n",
        "        steps[0] = 0\n",
        "        r_walks.append(100 + np.cumsum(steps))\n",
        "    r_walks_array = np.array(r_walks)\n",
        "\n",
        "    # Gather all simulation arrays to buffer of expected size/dtype on rank 0\n",
        "    r_walks_all = None\n",
        "    if rank == 0:\n",
        "        r_walks_all = np.empty([N * size, 100], dtype='float')\n",
        "    comm.Gather(sendbuf=r_walks_array, recvbuf=r_walks_all, root=0)\n",
        "\n",
        "    # Print/plot simulation results on rank 0\n",
        "    if rank == 0:\n",
        "        # Calculate time elapsed after computing mean and std\n",
        "        average_finish = np.mean(r_walks_all[:,-1])\n",
        "        std_finish = np.std(r_walks_all[:,-1])\n",
        "        time_elapsed = time.time() - t0\n",
        "\n",
        "        # Print time elapsed + simulation results\n",
        "        print(\"Simulated %d Random Walks in: %f seconds on %d MPI processes\"\n",
        "                % (n_runs, time_elapsed, size))\n",
        "        print(\"Average final position: %f, Standard Deviation: %f\"\n",
        "                % (average_finish, std_finish))\n",
        "\n",
        "        # Plot Simulations and save to file\n",
        "        plt.plot(r_walks_all.transpose())\n",
        "        plt.savefig(\"r_walk_nprocs%d_nruns%d.png\" % (size, n_runs))\n",
        "\n",
        "    return\n",
        "\n",
        "def main():\n",
        "    sim_rand_walks_parallel(n_runs=10000)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aEi_6YYkzyZ",
        "outputId": "399b293c-5c38-4dd6-b913-cc059ec0d653",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulated 10000 Random Walks in: 0.198135 seconds on 4 MPI processes\n",
            "Average final position: 100.111029, Standard Deviation: 9.894592\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -n 4 python mpi_rand_walk.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOS03ktfrxsOAG9ZslR4JHI",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "mpi4py_on_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
